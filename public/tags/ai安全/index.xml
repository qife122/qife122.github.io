<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>AI安全 on 办公AI智能小助手</title>
        <link>http://localhost:1313/tags/ai%E5%AE%89%E5%85%A8/</link>
        <description>Recent content in AI安全 on 办公AI智能小助手</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>zh-cn</language>
        <copyright>qife</copyright>
        <lastBuildDate>Thu, 07 Aug 2025 17:19:46 +0800</lastBuildDate><atom:link href="http://localhost:1313/tags/ai%E5%AE%89%E5%85%A8/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>保障指数级增长的AI供应链安全 - 思科技术解析</title>
        <link>http://localhost:1313/p/%E4%BF%9D%E9%9A%9C%E6%8C%87%E6%95%B0%E7%BA%A7%E5%A2%9E%E9%95%BF%E7%9A%84ai%E4%BE%9B%E5%BA%94%E9%93%BE%E5%AE%89%E5%85%A8-%E6%80%9D%E7%A7%91%E6%8A%80%E6%9C%AF%E8%A7%A3%E6%9E%90/</link>
        <pubDate>Thu, 07 Aug 2025 17:19:46 +0800</pubDate>
        
        <guid>http://localhost:1313/p/%E4%BF%9D%E9%9A%9C%E6%8C%87%E6%95%B0%E7%BA%A7%E5%A2%9E%E9%95%BF%E7%9A%84ai%E4%BE%9B%E5%BA%94%E9%93%BE%E5%AE%89%E5%85%A8-%E6%80%9D%E7%A7%91%E6%8A%80%E6%9C%AF%E8%A7%A3%E6%9E%90/</guid>
        <description>&lt;h3 id=&#34;全球ai竞赛与供应链风险&#34;&gt;全球AI竞赛与供应链风险
&lt;/h3&gt;&lt;p&gt;当前，AI模型平台HuggingFace以惊人的速度扩张——从100万模型增长至180万仅用9个月。各类供应商（包括未经验证的来源）通过该平台直接向开发者分发模型，导致网络安全等领域面临海量AI技术的同时，也引入了供应链风险，主要体现为：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;软件层&lt;/strong&gt;：库与框架漏洞&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;模型层&lt;/strong&gt;：文件内嵌恶意代码、架构后门&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;数据层&lt;/strong&gt;：训练数据污染、许可证合规问题&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;思科cerberus防护系统&#34;&gt;思科Cerberus防护系统
&lt;/h3&gt;&lt;p&gt;思科Foundation AI团队开发的Cerberus系统提供全天候自动化监测：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;实时扫描&lt;/strong&gt;：监控HuggingFace模型更新，分析潜在风险并生成标准化威胁报告。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;产品集成&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Secure Endpoint &amp;amp; Email&lt;/strong&gt;：阻断恶意文件读写及邮件附件传输。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Secure Web Gateway&lt;/strong&gt;：禁止下载含漏洞的模型，检查许可证合规性（如GPL协议风险），拦截地缘敏感区域（如DeepSeek）的未授权模型。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;风险检测技术&#34;&gt;风险检测技术
&lt;/h3&gt;&lt;p&gt;Cerberus结合元数据分析、沙箱检测和pickle文件审查等技术，识别以下威胁：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;代码执行&lt;/strong&gt;：利用&lt;code&gt;eval&lt;/code&gt;或&lt;code&gt;pwntools&lt;/code&gt;的反序列化攻击&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;系统控制&lt;/strong&gt;：通过&lt;code&gt;posix&lt;/code&gt;获取父系统权限&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;数据外泄&lt;/strong&gt;：使用&lt;code&gt;fabric.connection&lt;/code&gt;建立远程通道&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;合规性&lt;/strong&gt;：高风险开源许可证或供应商来源&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;策略执行机制&#34;&gt;策略执行机制
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Secure Web Gateway&lt;/strong&gt;：直接拦截HuggingFace的恶意模型下载。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Secure Email&lt;/strong&gt;：过滤含危险附件的邮件。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Secure Endpoint&lt;/strong&gt;：保护终端文件系统，阻止对可疑模型的读写。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;应对未来挑战&#34;&gt;应对未来挑战
&lt;/h3&gt;&lt;p&gt;随着AI代理参与代码开发的全流程，思科将持续优化防御技术，帮助安全团队快速响应新型威胁。&lt;/p&gt;
&lt;p&gt;&lt;em&gt;关注思科安全社交媒体（LinkedIn/Facebook/X）获取最新动态。&lt;/em&gt;&lt;/p&gt;
</description>
        </item>
        <item>
        <title>微软更新AI系统漏洞严重性分类标准</title>
        <link>http://localhost:1313/p/%E5%BE%AE%E8%BD%AF%E6%9B%B4%E6%96%B0ai%E7%B3%BB%E7%BB%9F%E6%BC%8F%E6%B4%9E%E4%B8%A5%E9%87%8D%E6%80%A7%E5%88%86%E7%B1%BB%E6%A0%87%E5%87%86/</link>
        <pubDate>Thu, 07 Aug 2025 14:44:41 +0800</pubDate>
        
        <guid>http://localhost:1313/p/%E5%BE%AE%E8%BD%AF%E6%9B%B4%E6%96%B0ai%E7%B3%BB%E7%BB%9F%E6%BC%8F%E6%B4%9E%E4%B8%A5%E9%87%8D%E6%80%A7%E5%88%86%E7%B1%BB%E6%A0%87%E5%87%86/</guid>
        <description>&lt;p&gt;微软安全响应中心(MSRC)始终致力于提高漏洞影响评估的透明度。我们正式发布《AI系统漏洞严重性分类标准》，这是对现有漏洞分类体系（即&amp;quot;漏洞评级标准&amp;quot;）的更新，专门涵盖AI产品中出现的新型漏洞类别。该框架旨在为外部研究者和微软安全团队提供更精细的漏洞影响评估依据。&lt;/p&gt;
&lt;h3 id=&#34;新增漏洞类别&#34;&gt;新增漏洞类别
&lt;/h3&gt;&lt;p&gt;本次更新包含三大顶级分类，每个分类下包含若干AI特有漏洞类型：&lt;/p&gt;
&lt;h4 id=&#34;1-推理操纵&#34;&gt;1. 推理操纵
&lt;/h4&gt;&lt;p&gt;此类漏洞可操纵AI模型对单个推理请求的响应，但不修改模型本身。包含两种新型漏洞：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;指令注入&lt;/strong&gt;：通过注入指令使模型偏离预期行为。与&amp;quot;提示注入&amp;quot;类似，但只有当注入内容能实质性改变模型行为时才构成漏洞（例如导致模型执行完全不同的任务）。攻击载体不限于文本输入，多模态模型中特制图像也可触发。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;输入扰动&lt;/strong&gt;：通过扰动合法输入导致模型输出错误结果（又称&amp;quot;对抗样本&amp;quot;）。需证明扰动能持续导致错误输出并产生明确安全影响才会被认定为漏洞。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;漏洞严重性取决于被操纵响应的应用场景。仅影响攻击者自身的情况暂不计入有效漏洞范围。&lt;/p&gt;
&lt;h4 id=&#34;2-模型操纵&#34;&gt;2. 模型操纵
&lt;/h4&gt;&lt;p&gt;涉及训练阶段模型篡改的漏洞，包含两种类型：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;模型投毒&lt;/strong&gt;：通过篡改模型架构、训练代码或超参数污染模型&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;数据投毒&lt;/strong&gt;：在训练前修改训练数据集&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;需证明投毒行为对最终模型产生可验证的影响（如植入可被特定输入触发的后门）。严重性取决于受影响模型的应用范围。&lt;/p&gt;
&lt;h4 id=&#34;3-推断性信息泄露&#34;&gt;3. 推断性信息泄露
&lt;/h4&gt;&lt;p&gt;可通过模型交互推断敏感信息的漏洞，包含多种子类型：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;推断特定数据是否用于训练（成员推断）&lt;/li&gt;
&lt;li&gt;推断训练数据的敏感属性（属性推断）&lt;/li&gt;
&lt;li&gt;推断模型架构/权重（模型窃取）&lt;/li&gt;
&lt;li&gt;提取系统提示（提示提取）&lt;/li&gt;
&lt;li&gt;推断其他用户输入（输入提取）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;评估标准取决于攻击者可达到的推断置信度/准确度，严重性根据受影响数据的敏感级别确定。&lt;/p&gt;
&lt;h3 id=&#34;与现有分类的关系&#34;&gt;与现有分类的关系
&lt;/h3&gt;&lt;p&gt;本次更新是对现有体系的补充，AI系统仍可能产生传统类型漏洞。例如：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;通过存储配置错误直接窃取模型权重属于现有&amp;quot;信息泄露&amp;quot;类别&lt;/li&gt;
&lt;li&gt;直接修改存储的模型权重属于&amp;quot;篡改&amp;quot;类别&lt;/li&gt;
&lt;li&gt;导致模型响应缓慢的漏洞属于&amp;quot;拒绝服务&amp;quot;类别&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;与其他分类体系的关联&#34;&gt;与其他分类体系的关联
&lt;/h3&gt;&lt;p&gt;新分类与MITRE ATLAS、OWASP LLM Top 10等现有 taxonomy 存在关联但不完全对应。值得注意的是，本次定义的漏洞类型不仅适用于大语言模型，还涵盖所有AI模态。&lt;/p&gt;
&lt;p&gt;微软将持续监控AI安全领域的发展动态，适时更新漏洞分类标准。我们欢迎安全研究者通过secure@microsoft.com提交漏洞报告，共同守护全球用户安全。&lt;/p&gt;
</description>
        </item>
        <item>
        <title>宣布推出AI/ML安全与防护培训课程</title>
        <link>http://localhost:1313/p/%E5%AE%A3%E5%B8%83%E6%8E%A8%E5%87%BAai/ml%E5%AE%89%E5%85%A8%E4%B8%8E%E9%98%B2%E6%8A%A4%E5%9F%B9%E8%AE%AD%E8%AF%BE%E7%A8%8B/</link>
        <pubDate>Thu, 07 Aug 2025 07:43:50 +0800</pubDate>
        
        <guid>http://localhost:1313/p/%E5%AE%A3%E5%B8%83%E6%8E%A8%E5%87%BAai/ml%E5%AE%89%E5%85%A8%E4%B8%8E%E9%98%B2%E6%8A%A4%E5%9F%B9%E8%AE%AD%E8%AF%BE%E7%A8%8B/</guid>
        <description>&lt;p&gt;我们今年将提供AI/ML安全与防护培训！&lt;/p&gt;
&lt;p&gt;AI/ML技术的最新进展为企业提升运营效率和改进服务产品开辟了新天地。然而，将AI/ML集成到计算系统中会带来全新且独特的复杂性、风险与攻击面。在协助客户安全部署这些系统的实践中，我们发现其安全团队在AI/ML与系统安全的交叉领域存在知识缺口。为此我们开发了本培训课程，帮助组织填补这一缺口，并为团队提供保护AI/ML操作流水线及技术栈的工具。&lt;/p&gt;
&lt;h3 id=&#34;培训课程内容&#34;&gt;培训课程内容
&lt;/h3&gt;&lt;p&gt;本课程专为需要理解传统计算基础设施上部署AI/ML系统特有安全挑战的安全工程师、ML工程师和IT人员设计。通过两天密集学习，您将获得从基础知识到可操作见解的全面认知，内容包括：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;AI/ML与网络安全基础&lt;/strong&gt;&lt;br&gt;
学习AI/ML模型/技术的工作原理、能力边界及局限性，同时涵盖ML工程师需要了解的软件安全核心知识。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;AI/ML技术栈与操作流水线&lt;/strong&gt;&lt;br&gt;
深入解析AI/ML模型从选择、配置、训练到部署及退役的全流程，并探讨相关专业技术工具。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;漏洞与修复方案&lt;/strong&gt;&lt;br&gt;
掌握已部署AI/ML系统特有的攻击面与漏洞类型，学习预防和修复这些漏洞的实战方法。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;风险评估与威胁建模&lt;/strong&gt;&lt;br&gt;
通过整体性方法，对AI/ML系统进行全面的风险评估和威胁建模，预判其对终端用户可能造成的安全风险。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;缓解措施与风险控制&lt;/strong&gt;&lt;br&gt;
实施针对AI/ML系统的现实风险缓解策略和安全控制方案，覆盖整个AI/ML操作流水线及生命周期。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;赋能安全与aiml融合领域的团队&#34;&gt;赋能安全与AI/ML融合领域的团队
&lt;/h3&gt;&lt;p&gt;Trail of Bits将前沿研究与实战经验相结合，持续推动AI/ML安全保证的技术发展。我们的专家团队可帮助您安全地运用AI/ML技术实现业务升级。立即联系我们为团队安排现场（或虚拟）培训。个人学习者可通过表格提交信息，以便在开放公开课程注册时获得通知。&lt;/p&gt;
&lt;p&gt;[Twitter] [LinkedIn] [GitHub] [Mastodon] [Hacker News]&lt;/p&gt;
</description>
        </item>
        <item>
        <title>近2000台MCP服务器存在严重安全漏洞：身份验证完全缺失</title>
        <link>http://localhost:1313/p/%E8%BF%912000%E5%8F%B0mcp%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%AD%98%E5%9C%A8%E4%B8%A5%E9%87%8D%E5%AE%89%E5%85%A8%E6%BC%8F%E6%B4%9E%E8%BA%AB%E4%BB%BD%E9%AA%8C%E8%AF%81%E5%AE%8C%E5%85%A8%E7%BC%BA%E5%A4%B1/</link>
        <pubDate>Tue, 05 Aug 2025 09:32:28 +0800</pubDate>
        
        <guid>http://localhost:1313/p/%E8%BF%912000%E5%8F%B0mcp%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%AD%98%E5%9C%A8%E4%B8%A5%E9%87%8D%E5%AE%89%E5%85%A8%E6%BC%8F%E6%B4%9E%E8%BA%AB%E4%BB%BD%E9%AA%8C%E8%AF%81%E5%AE%8C%E5%85%A8%E7%BC%BA%E5%A4%B1/</guid>
        <description>&lt;h1 id=&#34;近2000台mcp服务器存在完全安全缺失&#34;&gt;近2000台MCP服务器存在完全安全缺失
&lt;/h1&gt;&lt;p&gt;作为智能体AI核心组件的MCP（Model Context Protocol）服务器，其身份验证机制竟被设置为可选功能——而现实情况是根本无人启用它。这意味着攻击者可以轻松获得这些服务器的完全控制权。&lt;/p&gt;
&lt;h2 id=&#34;漏洞现状&#34;&gt;漏洞现状
&lt;/h2&gt;&lt;p&gt;网络安全研究人员通过扫描发现：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;当前暴露在互联网的&lt;strong&gt;1,862台MCP服务器&lt;/strong&gt;全部未配置任何访问控制&lt;/li&gt;
&lt;li&gt;测试样本中119台服务器均会无条件响应&lt;code&gt;tools/list&lt;/code&gt;请求，暴露所有可执行功能&lt;/li&gt;
&lt;li&gt;实际案例包括：汽车维修成本数据库、企业项目管理面板、法律案例库等敏感系统&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;攻击面分析&#34;&gt;攻击面分析
&lt;/h2&gt;&lt;p&gt;Knostic研究工程师Heather Linn指出：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&amp;ldquo;我们发现有人通过MCP暴露数据库连接器、云服务管理工具。有个汽车维修服务商用它管理维修进度和成本估算——这些数据都能被公开查询&amp;rdquo;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;潜在攻击方式包括：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;任意命令执行&lt;/strong&gt;：可能导致完整系统沦陷&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;数据泄露&lt;/strong&gt;：窃取API密钥、凭证等敏感信息&lt;/li&gt;
&lt;li&gt;&amp;ldquo;钱包耗尽&amp;quot;攻击(DoW)：恶意消耗受害者计算资源&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;技术根源&#34;&gt;技术根源
&lt;/h2&gt;&lt;p&gt;MCP协议存在双重问题：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;协议规范&lt;strong&gt;未强制要求认证机制&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;用户群体普遍缺乏安全意识：
&lt;ul&gt;
&lt;li&gt;相比传统云计算，AI技术&amp;quot;开箱即用&amp;quot;特性吸引了大量非专业用户&lt;/li&gt;
&lt;li&gt;开发者未将安全作为默认配置&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;行业响应&#34;&gt;行业响应
&lt;/h2&gt;&lt;p&gt;尽管Anthropic公司已更新规范：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;新版MCP仍&lt;strong&gt;未强制认证&lt;/strong&gt;，但提供了相关指南&lt;/li&gt;
&lt;li&gt;安全社区与厂商保持良好协作关系&lt;/li&gt;
&lt;li&gt;研究人员强调这是新技术发展必经的&amp;quot;成长阵痛&amp;rdquo;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;该事件暴露出AI基础设施在快速普及过程中面临严峻的安全挑战，亟需建立更严格的安全基线标准。&lt;/p&gt;
&lt;p&gt;&lt;em&gt;图：Panther Media Global via Alamy Stock Photo&lt;/em&gt;&lt;/p&gt;
</description>
        </item>
        <item>
        <title>NVIDIA容器工具包漏洞CVE-2024-0132补丁不完整，AI基础设施面临严重风险</title>
        <link>http://localhost:1313/p/nvidia%E5%AE%B9%E5%99%A8%E5%B7%A5%E5%85%B7%E5%8C%85%E6%BC%8F%E6%B4%9Ecve-2024-0132%E8%A1%A5%E4%B8%81%E4%B8%8D%E5%AE%8C%E6%95%B4ai%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD%E9%9D%A2%E4%B8%B4%E4%B8%A5%E9%87%8D%E9%A3%8E%E9%99%A9/</link>
        <pubDate>Tue, 05 Aug 2025 08:05:18 +0800</pubDate>
        
        <guid>http://localhost:1313/p/nvidia%E5%AE%B9%E5%99%A8%E5%B7%A5%E5%85%B7%E5%8C%85%E6%BC%8F%E6%B4%9Ecve-2024-0132%E8%A1%A5%E4%B8%81%E4%B8%8D%E5%AE%8C%E6%95%B4ai%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD%E9%9D%A2%E4%B8%B4%E4%B8%A5%E9%87%8D%E9%A3%8E%E9%99%A9/</guid>
        <description>&lt;h3 id=&#34;漏洞概述&#34;&gt;漏洞概述
&lt;/h3&gt;&lt;p&gt;趋势科技研究发现，NVIDIA在2024年9月针对容器工具包关键漏洞（CVE-2024-0132）发布的安全更新存在缺陷，可能导致容器逃逸攻击。同时发现影响Linux系统Docker的拒绝服务（DoS）漏洞，攻击者可利用这些漏洞访问主机敏感数据或耗尽系统资源。&lt;/p&gt;
&lt;h3 id=&#34;技术细节&#34;&gt;技术细节
&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;CVE-2024-0132补丁缺陷&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;时间竞争条件（TOCTOU）漏洞仍存在于NVIDIA容器工具包中，允许特制容器访问主机文件系统&lt;/li&gt;
&lt;li&gt;默认配置下1.17.3及更早版本均受影响，1.17.4版本需显式启用&lt;code&gt;allow-cuda-compat-libs-from-container&lt;/code&gt;功能才存在风险&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Docker拒绝服务漏洞&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;当容器配置多挂载点（bind-propagation=shared）时，Linux挂载表会无限增长&lt;/li&gt;
&lt;li&gt;最终导致文件描述符耗尽，主机SSH连接中断等严重性能问题&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;攻击场景&#34;&gt;攻击场景
&lt;/h3&gt;&lt;p&gt;攻击者可通过以下步骤实现容器逃逸：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;创建包含恶意卷符号链接的容器镜像&lt;/li&gt;
&lt;li&gt;通过供应链攻击或社会工程在受害者平台运行镜像&lt;/li&gt;
&lt;li&gt;利用竞争条件获取主机文件系统访问权限&lt;/li&gt;
&lt;li&gt;通过容器运行时Unix套接字执行任意root命令&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;防护建议&#34;&gt;防护建议
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;严格限制Docker API访问权限&lt;/li&gt;
&lt;li&gt;禁用NVIDIA容器工具包非必要功能&lt;/li&gt;
&lt;li&gt;实施容器镜像准入控制策略&lt;/li&gt;
&lt;li&gt;监控Linux挂载表异常增长&lt;/li&gt;
&lt;li&gt;部署运行时异常检测工具&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;趋势科技解决方案&#34;&gt;趋势科技解决方案
&lt;/h3&gt;&lt;p&gt;趋势Vision One™平台提供以下检测能力：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;观测攻击技术（OAT）：XSAE.F8306等规则&lt;/li&gt;
&lt;li&gt;工作负载行为（WB）检测：可疑容器创建等行为&lt;/li&gt;
&lt;li&gt;容器安全模块可阻断含漏洞镜像部署&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;图1-6展示了趋势Vision One的漏洞检测界面和告警示例（原文包含具体截图说明，此处从略）&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;完整补丁仍是首选解决方案，但在复杂生产环境中，趋势科技提供的运行时检测和预防措施可有效降低风险。平台已集成对CVE-2024-0132及新发现漏洞的检测能力，覆盖从构建到运行的全生命周期防护。&lt;/p&gt;
</description>
        </item>
        <item>
        <title>开源AI威胁建模工具——快速、情境感知且开发者友好</title>
        <link>http://localhost:1313/p/%E5%BC%80%E6%BA%90ai%E5%A8%81%E8%83%81%E5%BB%BA%E6%A8%A1%E5%B7%A5%E5%85%B7%E5%BF%AB%E9%80%9F%E6%83%85%E5%A2%83%E6%84%9F%E7%9F%A5%E4%B8%94%E5%BC%80%E5%8F%91%E8%80%85%E5%8F%8B%E5%A5%BD/</link>
        <pubDate>Mon, 04 Aug 2025 16:31:58 +0800</pubDate>
        
        <guid>http://localhost:1313/p/%E5%BC%80%E6%BA%90ai%E5%A8%81%E8%83%81%E5%BB%BA%E6%A8%A1%E5%B7%A5%E5%85%B7%E5%BF%AB%E9%80%9F%E6%83%85%E5%A2%83%E6%84%9F%E7%9F%A5%E4%B8%94%E5%BC%80%E5%8F%91%E8%80%85%E5%8F%8B%E5%A5%BD/</guid>
        <description>&lt;h1 id=&#34;开源ai威胁建模工具快速情境感知且开发者友好&#34;&gt;开源AI威胁建模工具——快速、情境感知且开发者友好
&lt;/h1&gt;&lt;p&gt;人工智能正在变革各行各业，但随之而来的安全风险也日益复杂。传统安全方法（如STRIDE框架）难以应对AI特有的威胁场景，例如：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;提示注入&lt;/strong&gt;：通过恶意输入操纵生成式AI行为&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;训练数据投毒&lt;/strong&gt;：污染数据集导致模型预测偏差&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;模型窃取&lt;/strong&gt;：通过API交互窃取模型参数&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;组件链风险&lt;/strong&gt;：向量数据库、API网关等组件的协同攻击面&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;工具核心能力&#34;&gt;工具核心能力
&lt;/h2&gt;&lt;p&gt;这款基于Streamlit构建的开源工具通过两阶段工作流实现威胁建模：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;交互式问卷&lt;/strong&gt;&lt;br&gt;
收集AI系统关键信息：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;模型类型（分类/生成/集成）&lt;/li&gt;
&lt;li&gt;数据来源（内部/爬取/用户生成）&lt;/li&gt;
&lt;li&gt;部署模式（SaaS/混合云）&lt;/li&gt;
&lt;li&gt;第三方依赖（开源模型/向量数据库）&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;规则引擎&lt;/strong&gt;&lt;br&gt;
基于300+条确定性规则生成：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;映射到MITRE ATLAS的攻击战术&lt;/li&gt;
&lt;li&gt;NIST CIA+Abuse分类&lt;/li&gt;
&lt;li&gt;合规缺口提示（GDPR/HIPAA）&lt;/li&gt;
&lt;li&gt;可操作的修复建议（如输入过滤、结构化提示）&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;技术实现&#34;&gt;技术实现
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;前端&lt;/strong&gt;：Streamlit构建的渐进式问卷&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;后端&lt;/strong&gt;：Python规则引擎，示例规则逻辑：&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-json&#34; data-lang=&#34;json&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nt&#34;&gt;&amp;#34;match&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;unfiltered_user_input&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;llm_used&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nt&#34;&gt;&amp;#34;threat&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;用户输入导致的提示注入&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nt&#34;&gt;&amp;#34;mitre_atlas&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;Prompt Injection&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nt&#34;&gt;&amp;#34;mitigations&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;输入消毒&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;结构化提示&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h2 id=&#34;适用场景&#34;&gt;适用场景
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;开发中的AI系统架构评审&lt;/li&gt;
&lt;li&gt;安全团队评估LLM应用风险&lt;/li&gt;
&lt;li&gt;产品经理向管理层解释AI风险&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;项目已在GitHub开源，支持本地部署：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;pip install -r requirements.txt
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;streamlit run main.py
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;未来版本计划集成OWASP LLM Top 10威胁图谱和团队协作功能。开发者可通过提交PR扩展威胁规则库，共同构建更安全的AI生态。&lt;/p&gt;
</description>
        </item>
        <item>
        <title>AI编程助手风险分析与应对策略</title>
        <link>http://localhost:1313/p/ai%E7%BC%96%E7%A8%8B%E5%8A%A9%E6%89%8B%E9%A3%8E%E9%99%A9%E5%88%86%E6%9E%90%E4%B8%8E%E5%BA%94%E5%AF%B9%E7%AD%96%E7%95%A5/</link>
        <pubDate>Sun, 03 Aug 2025 06:10:03 +0800</pubDate>
        
        <guid>http://localhost:1313/p/ai%E7%BC%96%E7%A8%8B%E5%8A%A9%E6%89%8B%E9%A3%8E%E9%99%A9%E5%88%86%E6%9E%90%E4%B8%8E%E5%BA%94%E5%AF%B9%E7%AD%96%E7%95%A5/</guid>
        <description>&lt;p&gt;随着ChatGPT等大型语言模型（LLM）的兴起，开发者正将这些工具实际应用于代码编写和理解场景。编程语言虽然结构严谨，但AI辅助编码仍存在多重风险，这正是我们撰写本技术白皮书的核心动因。&lt;/p&gt;
&lt;h3 id=&#34;主要使用场景&#34;&gt;主要使用场景
&lt;/h3&gt;&lt;p&gt;开发者主要通过三种方式使用这些工具：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;代码补全&lt;/strong&gt;：自动完成函数或代码行&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;代码解释&lt;/strong&gt;：解析现有代码逻辑&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;文档生成&lt;/strong&gt;：自动创建技术文档&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;其中代码补全功能的风险最为显著，工具可能直接输出包含漏洞的代码片段。&lt;/p&gt;
&lt;h3 id=&#34;核心风险分析&#34;&gt;核心风险分析
&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;安全输出无保障&lt;/strong&gt;&lt;br&gt;
研究证实（包括本文案例），这些工具会生成存在安全缺陷的代码。必须引入额外检测流程确保漏洞代码不会进入生产环境。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;一致性与可靠性问题&lt;/strong&gt;&lt;br&gt;
工具的输出质量受历史代码质量影响。即使模型本身具备安全输出能力，低质量的上下文代码仍会导致漏洞输出。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;数据泄露风险&lt;/strong&gt;&lt;br&gt;
GitHub Copilot等SaaS服务会收集IDE中的按键记录，包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;原始代码&lt;/li&gt;
&lt;li&gt;注释内容&lt;/li&gt;
&lt;li&gt;项目元数据&lt;br&gt;
这些数据可能被第三方存储分析，如图所示：&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;扩展建议&#34;&gt;扩展建议
&lt;/h3&gt;&lt;p&gt;本文仅列举部分风险，更详细的分析和缓解策略请下载完整版白皮书《Addressing Risks from AI Coding Assistants》。尽管研究主要针对GitHub Copilot和ChatGPT，但所述风险具有普适性，适用于各类AI编程辅助工具。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;特别警示：未来将有更多面向开发者的AI编程工具涌现，安全团队需要建立系统化的应对机制。&lt;/p&gt;&lt;/blockquote&gt;
</description>
        </item>
        
    </channel>
</rss>
