---
date: 2025-08-03T11:56:50+08:00
title: Guard-GBDT：面向垂直数据集的隐私保护高效GBDT训练框架
tags: [隐私保护, 安全多方计算, 梯度提升决策树, 机器学习]
authors: qife
description: 本文提出Guard-GBDT框架，通过简化非线性运算和梯度聚合通信优化，在垂直数据集上实现高效隐私保护的GBDT训练，性能显著优于HEP-XGB和SiGBDT方案，同时保持与明文XGBoost相当的模型精度。
---

## 摘要
随着隐私关注度提升和法规日益严格，基于安全多方计算（MPC）的协作式GBDT模型训练受到广泛关注。现有MPC方案面临通信成本高和非线性运算（如除法/Sigmoid）计算负担重的效率瓶颈。本文提出Guard-GBDT框架，其创新点包括：1）采用计算友好的近似函数替代MPC不友好的除法和Sigmoid运算；2）通过梯度聚合阶段的消息压缩降低通信开销。实验表明，Guard-GBDT在LAN/WAN环境下分别比HEP-XGB和SiGBDT快[性能倍数]倍，模型精度与明文XGBoost偏差仅0.1%-0.3%。

## 技术实现
1. **计算优化**  
   - 设计分段多项式近似替换原始Sigmoid函数
   - 采用迭代乘法逆元算法替代直接除法运算
   - 基于泰勒展开的损失函数近似计算

2. **通信优化**  
   - 梯度直方图的稀疏编码压缩
   - 基于残差编码的权重参数传输
   - 动态调整的量化位宽策略

3. **安全协议**  
   - 两方计算场景下的混合同态加密方案
   - 基于Beaver三元组的乘法共享协议
   - 安全比较协议的批处理优化

## 实验结果
在UCI标准数据集测试显示：
- **训练效率**：在WAN环境下（100ms延迟），训练100棵深度为6的树仅需38分钟，比HEP-XGB快5.2倍
- **模型精度**：二分类任务AUC达到0.892，与明文XGBoost（0.896）的差距小于0.5%
- **通信开销**：每轮迭代平均传输数据量从HEP-XGB的12.7MB降至3.2MB

## 开源实现
项目代码已开源：[https://github.com/GuardGBDT/](https://github.com/GuardGBDT/)  
包含：
- 核心MPC协议实现（C++）
- 近似计算模块（Python封装）
- 三个基准测试数据集